# ğŸ§  VisionVoice: Offline Multimodal AI Assistant

VisionVoice is a privacy-first, offline-capable AI assistant that helps visually impaired users understand images and printed text through OCR, image captioning, and voice commands â€” all without an internet connection.

## ğŸ” Features
- ğŸ“¸ Image captioning using BLIP
- ğŸ”  OCR using Tesseract
- ğŸ§  Offline TTS with `pyttsx3`
- ğŸ™ï¸ Vosk-based voice command recognition
- ğŸ“ Upload multiple images
- ğŸ“· Capture from webcam
- ğŸ“„ Export to TXT and PDF
- ğŸ” History tracking and clearing
- ğŸ§‘â€ğŸ’» Fully offline & privacy-first

## ğŸ§° Tech Stack
- Python, Streamlit
- BLIP for image captioning
- PyTesseract for OCR
- Pyttsx3 for offline speech
- Vosk for offline voice command
- OpenCV for webcam integration
- FPDF for PDF reports

## ğŸ“ Folder Structure
```
VisionVoice/
â”‚
â”œâ”€â”€ data/                          # Sample images or external input files
â”‚   â”œâ”€â”€ sample1.jpg
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ models/                        # Local model folders (Vosk, Gemma, etc.)
â”‚   â””â”€â”€ vosk-model-small-en-us-0.15/
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks for step-by-step development
â”‚   â”œâ”€â”€ 1_OCR_Text_Extraction.ipynb
â”‚   â”œâ”€â”€ 2_Image_Captioning.ipynb
â”‚   â”œâ”€â”€ 3_Text_Cleaning_and_Merge.ipynb
â”‚   â”œâ”€â”€ 4_Text_to_Speech.ipynb
â”‚   â”œâ”€â”€ 5_Check_Demo.ipynb
â”‚   â”œâ”€â”€ 6_Offline_TTS_pyttsx3.ipynb
â”‚   â””â”€â”€ 7_webcam_input_and_offline_tts.ipynb
â”‚
â”œâ”€â”€ app/                           # Streamlit app scripts and resources
â”‚   â””â”€â”€ streamlit_app.py
â”‚
â”œâ”€â”€ outputs/                       # Generated audio, text, and PDF outputs
â”‚   â”œâ”€â”€ image_1_description.txt
â”‚   â”œâ”€â”€ webcam_description.txt
â”‚   â”œâ”€â”€ visionvoice_history.txt
â”‚   â””â”€â”€ visionvoice_history.pdf
â”‚
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md                     # Project overview and instructions
â””â”€â”€ technical_writeup.md          # Architecture, features, model usage, etc.
```

## ğŸ› ï¸ Run the Streamlit App

```bash
streamlit run app/streamlit_app.py
```

## âœ… Requirements

Download the tesseract and vosk models. Save this files in models folder
1. https://github.com/tesseract-ocr/tesseract
2. https://alphacephei.com/vosk/models
   
Install all required dependencies:

```bash
pip install -r requirements.txt
```

## ğŸ“„ Example Commands

- "upload" â€” prompts user to upload image
- "webcam" â€” triggers webcam capture
- "history" â€” shows past processed items
- "clear history" â€” deletes history
- "export" â€” saves TXT + PDF
- "exit" â€” closes app

## ğŸ’¡ Use Case
Built for Google - Gemma 3n Impact Challenge to improve accessibility and independence for visually impaired users through fully offline, real-time image understanding.
